{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment07.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1UaVFBEY0cIuRdjsJCWgI8dAH9RPJkZGm",
      "authorship_tag": "ABX9TyOLIERlqyk1Qjii14lesi61",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fxnnxc/class-MachineLearning/blob/master/Assignment07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vJLoItsaHYp",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 07\n",
        "\n",
        "Logistic regression for a binary classification with a regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlkjTSlPaWP7",
        "colab_type": "text"
      },
      "source": [
        "## I. Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4bOHScHaaRl",
        "colab_type": "text"
      },
      "source": [
        "### 1.Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DAsDv87a2xK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data    = np.genfromtxt(\"data07.txt\", delimiter=',')\n",
        "pointX  = data[:, 0] \n",
        "pointY  = data[:, 1] \n",
        "label   = data[:, 2]\n",
        "\n",
        "pointX0 = pointX[label == 0] \n",
        "pointY0 = pointY[label == 0]\n",
        "pointX1 = pointX[label == 1] \n",
        "pointY1 = pointY[label == 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9esEBpyoagIT",
        "colab_type": "text"
      },
      "source": [
        "### 2. Logistic Regression with a high dimensional feature function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSNES9Q3_juQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "# haperparameters \n",
        "tht = [[0 for i in range(11)] for j in range(11)]\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "def sigmoid(x): #시그모이드 함수\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def G(x,y): #x,y에 대한 모델 \n",
        "  g = 0\n",
        "  for j in range(11):\n",
        "    for i in range(11):\n",
        "      g += tht[j][i]*(x**i)*(y**j)\n",
        "  return g\n",
        "\n",
        "def calculate_acc(data):#데이터에 대한 정확도 계산\n",
        "  correct = 0\n",
        "  for d in data:\n",
        "    if sigmoid(G(d[0],d[1]))>=1/2:\n",
        "      if d[2]==1:\n",
        "        correct +=1\n",
        "    else:\n",
        "      if d[2]==0:\n",
        "        correct +=1\n",
        "  return correct/len(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlLoQxE2agUZ",
        "colab_type": "text"
      },
      "source": [
        "### 3. Objective Function with a regularization term"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_cDY4aYdexd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lambda1 = 0\n",
        "lambda2 = 0.00000001\n",
        "lambda3 = 0.0000001\n",
        "\n",
        "def loss(data, lamb): #세타값에 대한 데이터의 로스\n",
        "    Z = [(G(d[0], d[1]) ,int(d[2])) for d in data] # Z값을 미리 계산해둔다. \n",
        "    entropy = sum([-z[1]*np.log(sigmoid(z[0]))-(1-z[1])*np.log(1-sigmoid(z[0])) for z in Z])/len(Z)  # 데이터와 세타\n",
        "    regularization =  lamb * sum([sum([tht[j][i]**2 for i in range(11)]) for j in range(11)])  # Regularization term\n",
        "    return entropy + regularization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez5IFzdoTd-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch04SPPZagoD",
        "colab_type": "text"
      },
      "source": [
        "### 4. Gradient Descent\n",
        "\n",
        "def gradient_descent():\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLbkngh1_0qP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent(lamb):\n",
        "  global tht\n",
        "  tht_buffer =[[0]*11]*11 # 변경 전 세타 값을 저장해서 한 번에 바꾼다. \n",
        "  sig = [G(d[0],d[1]) for d in data] # Z값을 미리 계산해둔다. \n",
        "  for j in range(11):\n",
        "    for i in range(11):\n",
        "      if i==0 and j==0:  # No regularization for theta 0,0\n",
        "          tht_buffer[0][0] = tht[0][0] - lr* sum([(sig[k] - d[2]) for k,d in enumerate(data)])/len(sig) \n",
        "      else:\n",
        "          tht_buffer[j][i] = tht[j][i]*(1-lr*lamb) - lr*(sum([(sig[k] - d[2])*(d[0]**i)*(d[1]**j) for k,d in enumerate(data)])/len(sig))\n",
        "  tht = tht_buffer[:] # tht 전역 변수에 업데이트된 세타값 저장"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woDa_UoSagxD",
        "colab_type": "text"
      },
      "source": [
        "### 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb3dmatZASyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "\n",
        "# Initialize\n",
        "J1 = [loss(data, lambda1)]\n",
        "J2 = [loss(data, lambda2)]\n",
        "J3 = [loss(data, lambda3)]\n",
        "\n",
        "ACC1 =[]\n",
        "ACC2 =[]\n",
        "ACC3 =[]\n",
        "\n",
        "tht_over = []\n",
        "tht_right= []\n",
        "tht_under= []\n",
        "\n",
        "# Training function\n",
        "def training(lamb,loss_list, acc_list, tht_store=None):\n",
        "    global tht, lr\n",
        "    tht = [[0]*11]*11 # theta for function \n",
        "    initial_lr = lr\n",
        "    J = loss(data, lamb)\n",
        "    stop = 10000\n",
        "    count = 0\n",
        "    print(\"Trainig started...\")\n",
        "    print(\"Proccessing   time\")\n",
        "    while True:\n",
        "      lr = initial_lr /(1+0.001*count) #learning rate annealing\n",
        "      gradient_descent(lamb)\n",
        "      acc_list.append(calculate_acc(data))\n",
        "      # Update and Store Loss\n",
        "      J = loss(data, lamb)\n",
        "      loss_list.append(J)\n",
        "      if count >stop : # Convergence\n",
        "        break\n",
        "      else:\n",
        "        if count %(stop/10) ==0:\n",
        "          print(\"- {0:3.0f}%        {1}\".format(count/stop*100, datetime.datetime.now().time().strftime(\"%H:%M:%S\") )) \n",
        "      count+=1\n",
        "    tht_store.append(tht)   # Append Final Theta\n",
        "    lr = initial_lr         # Restore Initial Learning Rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awa4-P_O_utf",
        "colab_type": "code",
        "outputId": "6d1c5453-8dce-4a8a-c99e-2b93e4002cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "training(lambda1, J1, ACC1, tht_over ) # Over  - fitting\n",
        "#training(lambda2, J2, ACC2, tht_right) # right - fitting\n",
        "#training(lambda3, J3, ACC3, tht_under) # under - fitting"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainig started...\n",
            "Proccessing   time\n",
            "-   0%        01:10:43\n",
            "-  10%        01:12:00\n",
            "-  20%        01:13:18\n",
            "-  30%        01:14:35\n",
            "-  40%        01:15:52\n",
            "-  50%        01:17:09\n",
            "-  60%        01:18:26\n",
            "-  70%        01:19:44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LcsgObXThRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decision Boundary\n",
        "# For Contour\n",
        "X_mesh, Y_mesh = np.meshgrid(np.linspace(-5.2,5.2, 100),\n",
        "                     np.linspace(-5.2, 5.2, 100))\n",
        "\n",
        "Z = [[],[],[]]\n",
        "tht_list = [tht_over, tht_right, tht_under]\n",
        "for i in range(3):\n",
        "  tht = tht_list[i][0]\n",
        "  z = G(X_mesh, Y_mesh)\n",
        "  for z1 in z:\n",
        "    Z[i].append([sigmoid(z2) for z2 in z1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQKMId_8aglB",
        "colab_type": "text"
      },
      "source": [
        "### 6. Accuracy\n",
        "\n",
        "Training을 하면서 Accuracy 또한 계산되며, 이는 ACC리스트에 저장된다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYBibm_Kageq",
        "colab_type": "text"
      },
      "source": [
        "## II. Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc2WiAPragb2",
        "colab_type": "text"
      },
      "source": [
        "### 1. The training data\n",
        "* label 0 = blue\n",
        "* label 1 = red"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHiSvG4FaFbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.scatter(pointX0, pointY0, c='b') \n",
        "plt.scatter(pointX1, pointY1, c='r') \n",
        "plt.tight_layout() \n",
        "plt.gca().set_aspect('equal', adjustable='box') \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn8IfXxBcJHj",
        "colab_type": "text"
      },
      "source": [
        "### 2. training error with varying regularization parameters\n",
        "\n",
        "* $g(x,y;\\theta) = {\\sum_{i=0}^{10}} {\\sum_{j=0}^{10}}\\theta_{i,j} x^iy^j$\n",
        "\n",
        "* $J(\\theta) = {1 \\over m }{\\sum_{i=0}^{m}} [-l^ilog(\\sigma(g(x^i,y^i;\\theta))) - (1-l^i)log(\\sigma(g(x^i,y^i;\\theta)))] + {\\lambda \\over 2m} {\\sum_{i=0}^{10}} {\\sum_{j=0}^{10}}\\theta_{i,j}^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC-Ucl5ncPai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(J1, c='r') \n",
        "plt.plot(J2, c='g') \n",
        "plt.plot(J3, c='b') \n",
        "plt.title('training error with varying regularization parameters')\n",
        "plt.legend(['over-fitting', 'just-right', 'under-fitting'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1rs7RJcJOZ",
        "colab_type": "text"
      },
      "source": [
        "### 3. The values of the chosen regularization parameteres $\\lambda$\n",
        "\n",
        "* $\\lambda_1$ :  over-fitting is demonstrated \n",
        "* $\\lambda_2$ :  just-right is demonstrated \n",
        "* $\\lambda_3$ :  under-fitting is demonstrated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7godUcKcPXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(['over fitting', 'just right', 'under fitting'], [lambda1,lambda2,lambda3], color=['r','g','b'])\n",
        "plt.text('over fitting', lambda1 , str(lambda1))\n",
        "plt.text('just right', lambda2 , str(lambda2))\n",
        "plt.text('under fitting', lambda3 , str(lambda3))\n",
        "plt.title('The values of the chosen regularization parameteres')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sQjoGzzcJRZ",
        "colab_type": "text"
      },
      "source": [
        "### 4. The training accuracy with varying regularaization parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lt5V8t3esrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(ACC1, c='r') \n",
        "plt.plot(ACC2, c='g') \n",
        "plt.plot(ACC3, c='b') \n",
        "plt.tight_layout() \n",
        "plt.title('training accuracy with varying regularization parameters')\n",
        "plt.legend(['over-fitting', 'just-right', 'under-fitting'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKYcNK2-cJZ6",
        "colab_type": "text"
      },
      "source": [
        "### 5.The final training accuracy with varying regularization parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxH81jxpe95E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(['over fitting', 'just right', 'under fitting'], [ACC1[-1], ACC2[-1], ACC3[-1]], color=['r','g','b'])\n",
        "plt.text('over fitting',ACC1[-1] , str(ACC1[-1]))\n",
        "plt.text('just right', ACC2[-1], str(ACC2[-1]))\n",
        "plt.text('under fitting', ACC3[-1] , str(ACC3[-1]))\n",
        "plt.title('The final training accuracy with varying regularization parameters')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSkbZk5ZcJWq",
        "colab_type": "text"
      },
      "source": [
        "### 6. The optimal classifier with varying regularization parameters superimposed on the training data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ITdYx_7bAbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = plt.figure(figsize=(10,10))\n",
        "plt.title('Optimal classifier')\n",
        "plt.scatter(pointX0, pointY0, alpha=1, c='b')\n",
        "plt.scatter(pointX1, pointY1, alpha=1, c='r')\n",
        "plt.contour(X_mesh, Y_mesh, Z[0],levels=[0.5],colors='red')   # Over\n",
        "plt.contour(X_mesh, Y_mesh, Z[1],levels=[0.5],colors='green') # Just right\n",
        "plt.contour(X_mesh, Y_mesh, Z[2],levels=[0.5],colors='blue')  # Under"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK79XY9-lN7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}